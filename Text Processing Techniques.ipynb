{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMat4yrN5z0IMisjHoPKSSO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\"\n","NAME: Sahab Mushtaq\n","Roll NO. BSAI-155\n","QUIZ LAB: 01\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"collapsed":true,"id":"h0YS8PaunRA5","executionInfo":{"status":"ok","timestamp":1742275242750,"user_tz":-300,"elapsed":38,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"84493f64-8305-4cc0-a6f9-8e7b6d1fe927"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nNAME: Sahab Mushtaq\\nRoll NO. BSAI-155\\nQUIZ LAB: 01\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["Part- 1\n","Tokenize the paragraph into words and remove punctuation marks."],"metadata":{"id":"U37M6MlusuAp"}},{"cell_type":"code","source":["import nltk\n","import string\n","import re\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt_tab')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"iTcSvOienRIg","executionInfo":{"status":"ok","timestamp":1742274450528,"user_tz":-300,"elapsed":884,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"f8e2409f-e291-46d2-d74c-1f78a31e1f20"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["paragraph = \"\"\"Natural Language Processing (NLP) is a fascinating field of artificial intelligence that focuses on\n","the interaction between humans and computers using natural language. It involves various\n","techniques such as tokenization, stemming, lemmatization, and semantic analysis to process and\n","analyze textual data. For example, removing stopwords like 'the' and 'is' can help reduce noise in\n","the text, while tasks like named entity recognition (NER) identify important entities such as\n","'Google' or 'New York.' Dependency parsing further reveals the grammatical structure of sentences,\n","enabling deeper insights into relationships between words. NLP techniques are widely applied in\n","applications like chatbots, sentiment analysis, and machine translation. For instance, a chatbot\n","might process 1,000 user queries per day, while sentiment analysis can classify text into categories\n","like positive (e.g., +1), neutral (0), or negative (-1). Additionally, machine translation systems can\n","translate up to 10 million words daily across multiple languages.\"\"\"\n","\n","words = word_tokenize(paragraph)\n","\n","clean_words = [word for word in words if word not in string.punctuation]\n","print(\"Output\")\n","print(\"Tokenizing the paragraph into words and removing punctuation marks.\")\n","print()\n","\n","print(clean_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAeQCi0En0gx","executionInfo":{"status":"ok","timestamp":1742275643246,"user_tz":-300,"elapsed":20,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"c8a468cd-e181-4f4e-e8c2-b2bca28723b0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Output\n","Tokenizing the paragraph into words and removing punctuation marks.\n","\n","['Natural', 'Language', 'Processing', 'NLP', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'humans', 'and', 'computers', 'using', 'natural', 'language', 'It', 'involves', 'various', 'techniques', 'such', 'as', 'tokenization', 'stemming', 'lemmatization', 'and', 'semantic', 'analysis', 'to', 'process', 'and', 'analyze', 'textual', 'data', 'For', 'example', 'removing', 'stopwords', 'like', \"'the\", 'and', \"'is\", 'can', 'help', 'reduce', 'noise', 'in', 'the', 'text', 'while', 'tasks', 'like', 'named', 'entity', 'recognition', 'NER', 'identify', 'important', 'entities', 'such', 'as', \"'Google\", 'or', \"'New\", 'York', 'Dependency', 'parsing', 'further', 'reveals', 'the', 'grammatical', 'structure', 'of', 'sentences', 'enabling', 'deeper', 'insights', 'into', 'relationships', 'between', 'words', 'NLP', 'techniques', 'are', 'widely', 'applied', 'in', 'applications', 'like', 'chatbots', 'sentiment', 'analysis', 'and', 'machine', 'translation', 'For', 'instance', 'a', 'chatbot', 'might', 'process', '1,000', 'user', 'queries', 'per', 'day', 'while', 'sentiment', 'analysis', 'can', 'classify', 'text', 'into', 'categories', 'like', 'positive', 'e.g.', '+1', 'neutral', '0', 'or', 'negative', '-1', 'Additionally', 'machine', 'translation', 'systems', 'can', 'translate', 'up', 'to', '10', 'million', 'words', 'daily', 'across', 'multiple', 'languages']\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","This code takes a paragraph of text about NLP and processes it by breaking it into individual words while removing punctuation marks. First, the paragraph is stored in a variable. Then, the word_tokenize function splits the text into separate words, treating punctuation as individual tokens. Next, a list comprehension filters out punctuation using string.punctuation, ensuring that only meaningful words remain. Finally, the cleaned words are printed. This process is essential in NLP tasks like text analysis, chatbots, and sentiment analysis, where removing punctuation helps AI models better understand and process text efficiently."],"metadata":{"id":"vC49f8vbuJnq"}},{"cell_type":"markdown","source":[],"metadata":{"id":"nr5txz8wsrGy"}},{"cell_type":"markdown","source":["Part-2\n"," Write a function to filter out numbers and special characters."],"metadata":{"id":"0eu7yuNYsyyp"}},{"cell_type":"code","source":["import re\n","\n","def filter_text(text):\n","    \"\"\"\n","    Removes numbers and special characters from the given text.\n","    Retains only alphabetic words and spaces.\n","    \"\"\"\n","    filtered_text = re.sub(r'[^A-Za-z\\s]', '', text)\n","    return filtered_text\n","\n","paragraph = \"\"\"Natural Language Processing (NLP) is a fascinating field of artificial intelligence that focuses on\n","the interaction between humans and computers using natural language. It involves various\n","techniques such as tokenization, stemming, lemmatization, and semantic analysis to process and\n","analyze textual data. For example, removing stopwords like 'the' and 'is' can help reduce noise in\n","the text, while tasks like named entity recognition (NER) identify important entities such as\n","'Google' or 'New York.' Dependency parsing further reveals the grammatical structure of sentences,\n","enabling deeper insights into relationships between words. NLP techniques are widely applied in\n","applications like chatbots, sentiment analysis, and machine translation. For instance, a chatbot\n","might process 1,000 user queries per day, while sentiment analysis can classify text into categories\n","like positive (e.g., +1), neutral (0), or negative (-1). Additionally, machine translation systems can\n","translate up to 10 million words daily across multiple languages.\"\"\"\n","\n","clean_text = filter_text(paragraph)\n","print(\"Output\")\n","print(\"Filtered out numbers and special characters:\")\n","print()\n","print(clean_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IuwnAIzIqMY5","executionInfo":{"status":"ok","timestamp":1742275992101,"user_tz":-300,"elapsed":14,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"5bf62ab2-e7c1-480c-ddf7-f65075241c8e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Output\n","Filtered out numbers and special characters:\n","\n","Natural Language Processing NLP is a fascinating field of artificial intelligence that focuses on\n","the interaction between humans and computers using natural language It involves various\n","techniques such as tokenization stemming lemmatization and semantic analysis to process and\n","analyze textual data For example removing stopwords like the and is can help reduce noise in\n","the text while tasks like named entity recognition NER identify important entities such as\n","Google or New York Dependency parsing further reveals the grammatical structure of sentences\n","enabling deeper insights into relationships between words NLP techniques are widely applied in\n","applications like chatbots sentiment analysis and machine translation For instance a chatbot\n","might process  user queries per day while sentiment analysis can classify text into categories\n","like positive eg  neutral  or negative  Additionally machine translation systems can\n","translate up to  million words daily across multiple languages\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","This code defines a function filter_text that removes numbers and special characters from a given text, keeping only alphabetic words and spaces. It uses the re.sub function with the pattern [^A-Za-z\\s], which matches anything that is not a letter (A-Z, a-z) or a space, replacing it with an empty string. The function is then applied to a paragraph about NLP, filtering out punctuation, numbers, and special symbols while retaining meaningful text. Finally, the cleaned text is printed, making it more suitable for NLP tasks like text analysis or machine learning preprocessing."],"metadata":{"id":"rrhhMBNNuc1S"}},{"cell_type":"markdown","source":["Part-3. Validate if the given text contains profanity using profanity-check."],"metadata":{"id":"mHl7h2nrs3gK"}},{"cell_type":"markdown","source":[],"metadata":{"id":"RWFGVAyHub9C"}},{"cell_type":"code","source":["!pip install profanity-check\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"qNHjxnEqqzjL","executionInfo":{"status":"ok","timestamp":1742274983588,"user_tz":-300,"elapsed":3423,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"b916ae72-3545-4355-d73a-34132b5c211c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: profanity-check in /usr/local/lib/python3.11/dist-packages (1.0.3)\n","Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from profanity-check) (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.14.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->profanity-check) (3.6.0)\n"]}]},{"cell_type":"code","source":["!pip install better-profanity\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"peL54XHWrgWk","executionInfo":{"status":"ok","timestamp":1742274986305,"user_tz":-300,"elapsed":2713,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"cd0d3ca0-bfe5-4a9d-ced4-fc151fa663c7"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: better-profanity in /usr/local/lib/python3.11/dist-packages (0.7.0)\n"]}]},{"cell_type":"code","source":["from better_profanity import profanity\n","\n","paragraph = \"\"\"\"Natural Language Processing (NLP) is a fascinating field of artificial intelligence that focuses on\n","the interaction between humans and computers using natural language. It involves various\n","techniques such as tokenization, stemming, lemmatization, and semantic analysis to process and\n","analyze textual data. For example, removing stopwords like 'the' and 'is' can help reduce noise in\n","the text, while tasks like named entity recognition (NER) identify important entities such as\n","'Google' or 'New York.' Dependency parsing further reveals the grammatical structure of sentences,\n","enabling deeper insights into relationships between words. NLP techniques are widely applied in\n","applications like chatbots, sentiment analysis, and machine translation. For instance, a chatbot\n","might process 1,000 user queries per day, while sentiment analysis can classify text into categories\n","like positive (e.g., +1), neutral (0), or negative (-1). Additionally, machine translation systems can\n","translate up to 10 million words daily across multiple languages\"\"\"\n","\n","print(\"Output\")\n","if profanity.contains_profanity(paragraph):\n","    print(\"Profanity detected!\")\n","else:\n","    print(\" No profanity detected.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFHuF7PprPPa","executionInfo":{"status":"ok","timestamp":1742276030663,"user_tz":-300,"elapsed":279,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"a3f61fd8-3be2-4350-b3a0-2afb6b3a8bae"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Output\n"," No profanity detected.\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","This code checks whether a given paragraph contains profanity using the better_profanity library. First, the paragraph is stored as a string. The function profanity.contains_profanity(paragraph) scans the text for offensive words. If any profanity is found, it prints \"Profanity detected!\", otherwise, it prints \"No profanity detected.\" This is useful in applications like content moderation, chat filters, or automated text screening to ensure clean and appropriate language in user-generated content."],"metadata":{"id":"7Afa8L6yuumC"}},{"cell_type":"markdown","source":["Part-4 Perform stemming on a given text using the Porter Stemmer algorithm"],"metadata":{"id":"-zjiLMsWtAFi"}},{"cell_type":"code","source":["import nltk\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","\n","# Download the required NLTK resources\n","nltk.download('punkt')\n","\n","# Initialize the Porter Stemmer\n","stemmer = PorterStemmer()\n","\n","# Given paragraph\n","paragraph = \"\"\" Natural Language Processing (NLP) is a fascinating field of artificial intelligence that focuses on\n","the interaction between humans and computers using natural language. It involves various\n","techniques such as tokenization, stemming, lemmatization, and semantic analysis to process and\n","analyze textual data. For example, removing stopwords like 'the' and 'is' can help reduce noise in\n","the text, while tasks like named entity recognition (NER) identify important entities such as\n","'Google' or 'New York.' Dependency parsing further reveals the grammatical structure of sentences,\n","enabling deeper insights into relationships between words. NLP techniques are widely applied in\n","applications like chatbots, sentiment analysis, and machine translation. For instance, a chatbot\n","might process 1,000 user queries per day, while sentiment analysis can classify text into categories\n","like positive (e.g., +1), neutral (0), or negative (-1). Additionally, machine translation systems can\n","translate up to 10 million words daily across multiple languages.\"\"\"\n","\n","words = word_tokenize(paragraph)\n","\n","stemmed_words = [stemmer.stem(word) for word in words]\n","print(\"Output\")\n","print(\"Original Words:\", words)\n","print(\"\\nStemmed Words:\", stemmed_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wUd49bjsCja","executionInfo":{"status":"ok","timestamp":1742276060975,"user_tz":-300,"elapsed":54,"user":{"displayName":"Sahab Muhstaq","userId":"16714411566182042431"}},"outputId":"0b71ade5-39d0-4a74-b0fd-183a6e64bfba"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Output\n","Original Words: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'humans', 'and', 'computers', 'using', 'natural', 'language', '.', 'It', 'involves', 'various', 'techniques', 'such', 'as', 'tokenization', ',', 'stemming', ',', 'lemmatization', ',', 'and', 'semantic', 'analysis', 'to', 'process', 'and', 'analyze', 'textual', 'data', '.', 'For', 'example', ',', 'removing', 'stopwords', 'like', \"'the\", \"'\", 'and', \"'is\", \"'\", 'can', 'help', 'reduce', 'noise', 'in', 'the', 'text', ',', 'while', 'tasks', 'like', 'named', 'entity', 'recognition', '(', 'NER', ')', 'identify', 'important', 'entities', 'such', 'as', \"'Google\", \"'\", 'or', \"'New\", 'York', '.', \"'\", 'Dependency', 'parsing', 'further', 'reveals', 'the', 'grammatical', 'structure', 'of', 'sentences', ',', 'enabling', 'deeper', 'insights', 'into', 'relationships', 'between', 'words', '.', 'NLP', 'techniques', 'are', 'widely', 'applied', 'in', 'applications', 'like', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.', 'For', 'instance', ',', 'a', 'chatbot', 'might', 'process', '1,000', 'user', 'queries', 'per', 'day', ',', 'while', 'sentiment', 'analysis', 'can', 'classify', 'text', 'into', 'categories', 'like', 'positive', '(', 'e.g.', ',', '+1', ')', ',', 'neutral', '(', '0', ')', ',', 'or', 'negative', '(', '-1', ')', '.', 'Additionally', ',', 'machine', 'translation', 'systems', 'can', 'translate', 'up', 'to', '10', 'million', 'words', 'daily', 'across', 'multiple', 'languages', '.']\n","\n","Stemmed Words: ['natur', 'languag', 'process', '(', 'nlp', ')', 'is', 'a', 'fascin', 'field', 'of', 'artifici', 'intellig', 'that', 'focus', 'on', 'the', 'interact', 'between', 'human', 'and', 'comput', 'use', 'natur', 'languag', '.', 'it', 'involv', 'variou', 'techniqu', 'such', 'as', 'token', ',', 'stem', ',', 'lemmat', ',', 'and', 'semant', 'analysi', 'to', 'process', 'and', 'analyz', 'textual', 'data', '.', 'for', 'exampl', ',', 'remov', 'stopword', 'like', \"'the\", \"'\", 'and', \"'i\", \"'\", 'can', 'help', 'reduc', 'nois', 'in', 'the', 'text', ',', 'while', 'task', 'like', 'name', 'entiti', 'recognit', '(', 'ner', ')', 'identifi', 'import', 'entiti', 'such', 'as', \"'googl\", \"'\", 'or', \"'new\", 'york', '.', \"'\", 'depend', 'pars', 'further', 'reveal', 'the', 'grammat', 'structur', 'of', 'sentenc', ',', 'enabl', 'deeper', 'insight', 'into', 'relationship', 'between', 'word', '.', 'nlp', 'techniqu', 'are', 'wide', 'appli', 'in', 'applic', 'like', 'chatbot', ',', 'sentiment', 'analysi', ',', 'and', 'machin', 'translat', '.', 'for', 'instanc', ',', 'a', 'chatbot', 'might', 'process', '1,000', 'user', 'queri', 'per', 'day', ',', 'while', 'sentiment', 'analysi', 'can', 'classifi', 'text', 'into', 'categori', 'like', 'posit', '(', 'e.g.', ',', '+1', ')', ',', 'neutral', '(', '0', ')', ',', 'or', 'neg', '(', '-1', ')', '.', 'addit', ',', 'machin', 'translat', 'system', 'can', 'translat', 'up', 'to', '10', 'million', 'word', 'daili', 'across', 'multipl', 'languag', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","This code performs stemming on a given paragraph using the Porter Stemmer algorithm from the NLTK library. It first tokenizes the paragraph into individual words, then applies stemming to reduce each word to its root form (e.g., running → run, processing → process). The purpose of stemming is to simplify words for text analysis, search engines, and NLP applications by reducing variations of words to a common base. Finally, it prints both the original and stemmed words, demonstrating how words are transformed for easier processing in machine learning and language-related tasks."],"metadata":{"id":"RBuTblhzvAwC"}}]}