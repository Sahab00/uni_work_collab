{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahab00/uni_work_collab/blob/main/Neural_Network_initial_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca11576-1860-427c-a9a9-9fe9ce71662a",
      "metadata": {
        "id": "aca11576-1860-427c-a9a9-9fe9ce71662a"
      },
      "source": [
        "Excercise\n",
        "The torch package has been imported,\n",
        ".\n",
        ".\n",
        ".\n",
        "4.Add the resulting tensors, tensor_c and tensor_d, from the two previous steps together and assign it to tensor_e."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca52954e-6739-433b-b21c-d0bf744b9730",
      "metadata": {
        "id": "ca52954e-6739-433b-b21c-d0bf744b9730",
        "outputId": "9ae4f8b4-a604-4eee-e877-3385a7c7ef42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  7, 11],\n",
            "        [13, 13, 11]], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Create two arrays\n",
        "array_a = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "array_b = np.array([[6, 5, 4], [3, 2, 1]])\n",
        "\n",
        "# Create two tensors from the arrays\n",
        "tensor_a = torch.from_numpy(array_a)\n",
        "tensor_b = torch.from_numpy(array_b)\n",
        "\n",
        "# Subtract tensor_b from tensor_a\n",
        "tensor_c = tensor_a - tensor_b\n",
        "\n",
        "# Multiply each element of tensor_a with each element of tensor_b (element-wise multiplication)\n",
        "tensor_d = tensor_a * tensor_b\n",
        "\n",
        "# Add tensor_c to tensor_d\n",
        "tensor_e = tensor_c + tensor_d\n",
        "\n",
        "print(tensor_e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b66f00-8849-411a-9f71-a8c2af490314",
      "metadata": {
        "id": "91b66f00-8849-411a-9f71-a8c2af490314"
      },
      "source": [
        "Excercise\n",
        "Your first neural network\n",
        "\n",
        "In this exercise,\n",
        ".\n",
        ".\n",
        ".\n",
        "Use any output dimension for the first layer you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac111a3-ce2e-4164-bcb3-227b9fdc0783",
      "metadata": {
        "id": "cac111a3-ce2e-4164-bcb3-227b9fdc0783",
        "outputId": "581bf96a-9125-4c9c-86a1-1438c8aa7924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.6591]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
        "\n",
        "# Implement a small neural network with exactly two linear layers\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 4),  # First layer takes 8 inputs and outputs 4\n",
        "    nn.ReLU(),        # Activation functionS\n",
        "    nn.Linear(4, 1)   # Second layer takes 4 inputs and outputs 1\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4445017c-07d2-40fc-9b4e-e62f83a28d1f",
      "metadata": {
        "id": "4445017c-07d2-40fc-9b4e-e62f83a28d1f",
        "outputId": "686f34bf-ed46-4560-d1f1-39dd7c37b108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9197, -0.4636]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Input tensor (1x12)\n",
        "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1, 5, 3, 6, 9]])\n",
        "\n",
        "# Define the neural network with three hidden layers and an output of size 2\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(12, 20), # First layer\n",
        "    nn.Linear(20, 14), # Second layer\n",
        "    nn.Linear(14, 3),  # Third layer\n",
        "    nn.Linear(3, 2)    # Output layer\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3168445c-dba4-4279-95a8-34f57ed27172",
      "metadata": {
        "id": "3168445c-dba4-4279-95a8-34f57ed27172",
        "outputId": "35cc2a94-7502-4455-94fb-4998e49e851d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sigmoid Probability: tensor([[0.6900]])\n",
            "Softmax Probability: tensor([[1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input_tensor = torch.tensor([[0.8]])\n",
        "\n",
        "# Create a sigmoid function and apply it on input_tensor\n",
        "sigmoid = torch.sigmoid(input_tensor)\n",
        "probability_sigmoid = sigmoid\n",
        "print(\"Sigmoid Probability:\", probability_sigmoid)\n",
        "\n",
        "# Create a softmax function and apply it on input_tensor\n",
        "softmax = torch.softmax(input_tensor, dim=1)\n",
        "probability_softmax = softmax\n",
        "print(\"Softmax Probability:\", probability_softmax)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f673759-e1fa-4b78-9ea9-63e0f2d5a00e",
      "metadata": {
        "id": "8f673759-e1fa-4b78-9ea9-63e0f2d5a00e",
        "outputId": "ccd8b063-9f00-463c-947b-bda7f5152ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sigmoid Probability: tensor([[0.6900]])\n",
            "Softmax Probability: tensor([[1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input_tensor = torch.tensor([[0.8]])\n",
        "\n",
        "# Create a sigmoid function and apply it on input_tensor\n",
        "sigmoid = torch.sigmoid(input_tensor)\n",
        "probability_sigmoid = sigmoid\n",
        "print(\"Sigmoid Probability:\", probability_sigmoid)\n",
        "\n",
        "# Create a softmax function and apply it on input_tensor\n",
        "softmax = torch.softmax(input_tensor, dim=1)\n",
        "probability_softmax = softmax\n",
        "print(\"Softmax Probability:\", probability_softmax)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799b9077-ecd6-4a38-96d2-e25dbec362a9",
      "metadata": {
        "id": "799b9077-ecd6-4a38-96d2-e25dbec362a9",
        "outputId": "4368bcf7-d7d7-4284-a5cb-3a0a6b177c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9817]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
        "\n",
        "# Implement a small neural network for binary classification\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 1),  # One input (8 features) to one output\n",
        "    nn.Sigmoid()      # Sigmoid activation for binary classification\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5cf058-127d-46b7-9593-f571b10f7c51",
      "metadata": {
        "id": "3b5cf058-127d-46b7-9593-f571b10f7c51",
        "outputId": "9f9bd840-534a-4388-86ea-6d8e9cb189ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.5510]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
        "\n",
        "# Implement a neural network with exactly four linear layers for regression\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(11, 20), # Example sizes for hidden layers\n",
        "    nn.Linear(20, 15),\n",
        "    nn.Linear(15, 10),\n",
        "    nn.Linear(10, 1)   # Output layer for regression\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe9fcb1-a01b-428b-827c-bde0b0c7b4e9",
      "metadata": {
        "id": "0fe9fcb1-a01b-428b-827c-bde0b0c7b4e9",
        "outputId": "c9597842-0dae-495a-edc8-ca7b0989b19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.0606, -0.4228, -0.7738, -1.5641]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
        "\n",
        "# Update network to perform a multi-class classification with four labels\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(11, 20), # Example sizes for hidden layers\n",
        "    nn.Linear(20, 15),\n",
        "    nn.Linear(15, 10),\n",
        "    nn.Linear(10, 4)   # Output layer with 4 outputs for multi-class\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7383a7d7-7cd7-4438-8902-de7308873783",
      "metadata": {
        "id": "7383a7d7-7cd7-4438-8902-de7308873783"
      },
      "outputs": [],
      "source": [
        "#Exercise 4: True Statements about Neural Networks\n",
        "\n",
        "True: A neural network with a single linear layer followed by a sigmoid activation is similar to a logistic regression model.\n",
        "False: A neural network can only contain two linear layers.\n",
        "False: The softmax function takes a tensor of dimension N as input and outputs a float between zero and one. (It outputs a tensor where each element is between 0 and 1 and sums to 1.)\n",
        "True: The input dimension of a linear layer must be equal to the output dimension of the previous layer."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}