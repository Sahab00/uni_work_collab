{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahab00/uni_work_collab/blob/main/Text_preprocessing_removing_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da9522a",
      "metadata": {
        "id": "4da9522a"
      },
      "source": [
        "'''\n",
        "You will load the Movies.csv file and load it as data frame in Python.\n",
        "Now analyze the dataset and carry out all the text pre-processing steps on the Overview.\n",
        "Carry out maximum data cleaning tasks and in the end carry out Tokenization, stemming and Lemmatization\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a04849",
      "metadata": {
        "id": "58a04849"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df= pd.read_csv(\"movies.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf97c5c",
      "metadata": {
        "id": "dbf97c5c",
        "outputId": "082b7418-f35e-4db6-fd48-6b473186f07a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Film', 'Genre', 'Lead Studio', 'Audience score %', 'Profitability',\n",
            "       'Rotten Tomatoes %', 'Worldwide Gross', 'Year'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Print the column names to identify the correct column\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6515fb",
      "metadata": {
        "id": "1b6515fb",
        "outputId": "47bd3f49-78af-407b-f4c4-9e767f246b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                  Film             cleaned_film\n",
            "0           Zack and Miri Make a Porno     zack miri make porno\n",
            "1                      Youth in Revolt             youth revolt\n",
            "2   You Will Meet a Tall Dark Stranger  meet tall dark stranger\n",
            "3                         When in Rome                     rome\n",
            "4                What Happens in Vegas            happens vegas\n",
            "..                                 ...                      ...\n",
            "72                 Across the Universe          across universe\n",
            "73                       A Serious Man              serious man\n",
            "74                  A Dangerous Method         dangerous method\n",
            "75                          27 Dresses               27 dresses\n",
            "76                (500) Days of Summer          500 days summer\n",
            "\n",
            "[77 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re  #Clean text data\n",
        "import string   #acces to punctuation\n",
        "\n",
        "# Define a simple list of stopwords (you can expand this list as needed)\n",
        "stop_words = set([\n",
        "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
        "    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\",\n",
        "    \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\",\n",
        "    \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\",\n",
        "    \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\",\n",
        "    \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\",\n",
        "    \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\",\n",
        "    \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\",\n",
        "    \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\",\n",
        "    \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\",\n",
        "    \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\", \"d\", \"ll\",\n",
        "    \"m\", \"o\", \"re\", \"ve\", \"y\", \"ain\", \"aren\", \"couldn\", \"didn\", \"doesn\", \"hadn\", \"hasn\", \"haven\",\n",
        "    \"isn\", \"ma\", \"mightn\", \"mustn\", \"needn\", \"shan\", \"shouldn\", \"wasn\", \"weren\", \"won\", \"wouldn\"\n",
        "])\n",
        "\n",
        "# Function for cleaning and preprocessing text\n",
        "def preprocess_text(text):\n",
        "    # Lowercasing the text\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove emojis (simple regex to match emojis)\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    # Tokenization (split by spaces)\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Chat words treatment (optional, here we do a simple example)\n",
        "    chat_dict = {\"u\": \"you\", \"r\": \"are\", \"lol\": \"laughing out loud\"}\n",
        "    tokens = [chat_dict.get(word, word) for word in tokens]\n",
        "\n",
        "    # Rejoin tokens into a string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('movies.csv')\n",
        "\n",
        "# Clean the column names (if there are any extra spaces)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Choose a column to apply the preprocessing (for example, 'Film')\n",
        "df['cleaned_film'] = df['Film'].apply(preprocess_text)\n",
        "\n",
        "# Save the cleaned data back to a new CSV file\n",
        "df.to_csv('movies_cleaned.csv', index=False)\n",
        "\n",
        "# Display the cleaned data\n",
        "print(df[['Film', 'cleaned_film']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b37234",
      "metadata": {
        "id": "08b37234"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f93590b",
      "metadata": {
        "id": "1f93590b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}